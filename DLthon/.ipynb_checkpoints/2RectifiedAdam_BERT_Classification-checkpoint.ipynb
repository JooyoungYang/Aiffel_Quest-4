{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "094725fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb20bd8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx      class                                       conversation\n",
       "0    0      협박 대화  지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...\n",
       "1    1      협박 대화  길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...\n",
       "2    2  기타 괴롭힘 대화  너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...\n",
       "3    3      갈취 대화  어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...\n",
       "4    4      갈취 대화  저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_path = \"~/data/train.csv\"\n",
    "train_df = pd.read_csv(train_df_path)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e65c3ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>갈취 대화</th>\n",
       "      <td>981</td>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>기타 괴롭힘 대화</th>\n",
       "      <td>1094</td>\n",
       "      <td>1094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>직장 내 괴롭힘 대화</th>\n",
       "      <td>979</td>\n",
       "      <td>979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>협박 대화</th>\n",
       "      <td>896</td>\n",
       "      <td>896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              idx  conversation\n",
       "class                          \n",
       "갈취 대화         981           981\n",
       "기타 괴롭힘 대화    1094          1094\n",
       "직장 내 괴롭힘 대화   979           979\n",
       "협박 대화         896           896"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby(by=['class']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c362bb",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2f75178",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encode = {\n",
    "    \"협박 대화\" : 0,\n",
    "    \"갈취 대화\" : 1,\n",
    "    \"직장 내 괴롭힘 대화\" : 2,\n",
    "    \"기타 괴롭힘 대화\" : 3,   \n",
    "}\n",
    "train_df['encoded_label'] = train_df['class'].map(label_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9356628e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       3\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "3945    3\n",
       "3946    1\n",
       "3947    2\n",
       "3948    1\n",
       "3949    2\n",
       "Name: encoded_label, Length: 3950, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['encoded_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accef61c",
   "metadata": {},
   "source": [
    "### Spliting data into training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7704facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train_df['conversation'].to_list()\n",
    "train_labels = train_df['encoded_label'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7b0e6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Stratified Split Train and Validation data \n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.2, random_state=1000, stratify=train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e73abf8",
   "metadata": {},
   "source": [
    "# 2. Tokenizing the text\n",
    "## Load Tokenizer and Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e37b959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"klue/bert-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b79ab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "from transformers import BertModel\n",
    "\n",
    "\n",
    "# Load Tokenizer \n",
    "tokenizer = BertTokenizerFast.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# Tokenizing\n",
    "# dict_keys(['input_ids', 'token_type_ids', 'attention_mask']) 이런식으로 \n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True) \n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ceaa015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "print(dict(val_encodings).keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcdd963",
   "metadata": {},
   "source": [
    "# 3. Creating a Dataset Object for Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91e74c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# trainset-set\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    "))\n",
    "\n",
    "# validation-set\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_labels\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5f10a5",
   "metadata": {},
   "source": [
    "# 4. Fine-Tuning BERT\n",
    "## 4.1 Using Native Tensorflow pipeline\n",
    "### Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c02e988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertForSequenceClassification\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "num_labels = len(label_encode)\n",
    "print(num_labels)\n",
    "# TODO : from_pt=False 혹은 없이 해보기\n",
    "# from_pt – (optional) boolean, default False: Load the model weights from a PyTorch state_dict save file (see docstring of pretrained_model_name_or_path argument).\n",
    "model = TFBertForSequenceClassification.from_pretrained(MODEL_PATH, num_labels=num_labels, from_pt=True)\n",
    "\n",
    "optimizer = tfa.optimizers.RectifiedAdam(lr=5.0e-5, total_steps = 2344*4, warmup_proportion=0.1, min_lr=1e-5, epsilon=1e-08, clipnorm=1.0)\n",
    "model.compile(optimizer=optimizer, loss=model.compute_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9fcb609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method TFSequenceClassificationLoss.compute_loss of <transformers.models.bert.modeling_tf_bert.TFBertForSequenceClassification object at 0x7ff56681bb80>>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compute_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502432d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "395/395 [==============================] - ETA: 0s - loss: 1.1612 - accuracy: 0.4987"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint\n",
    "\n",
    "callback_earlystopping = EarlyStopping(\n",
    "    monitor=\"val_accuracy\", \n",
    "    min_delta=0.001, # the threshold that triggers the termination (acc should at least improve 0.001)\n",
    "    patience=2)\n",
    "\n",
    "callback_learningrate_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    min_delta=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=0,\n",
    ")\n",
    "\n",
    "\n",
    "callback_modelcheckpoint = ModelCheckpoint(\n",
    "    filepath = \"BERT_BestModel.keras\",\n",
    "    monitor=\"vall_accuracy\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "callback_list = [callback_earlystopping, callback_learningrate_scheduler, callback_modelcheckpoint]\n",
    "\n",
    "model.fit(\n",
    "    train_dataset.shuffle(1000).batch(8), epochs=5, batch_size=4,\n",
    "    validation_data=val_dataset.shuffle(1000).batch(16),\n",
    "    callbacks = callback_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb22675",
   "metadata": {},
   "source": [
    "### Saving the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea551cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'fine-tuned-klue-bert-base'\n",
    "MODEL_SAVE_PATH = os.path.join(\"_model\", MODEL_NAME) # change this to your preferred location\n",
    "\n",
    "if os.path.exists(MODEL_SAVE_PATH):\n",
    "    print(f\"{MODEL_SAVE_PATH} -- Folder already exists \\n\")\n",
    "else:\n",
    "    os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
    "    print(f\"{MODEL_SAVE_PATH} -- Folder create complete \\n\")\n",
    "\n",
    "# save tokenizer, model\n",
    "model.save_pretrained(MODEL_SAVE_PATH)\n",
    "tokenizer.save_pretrained(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a556394",
   "metadata": {},
   "source": [
    "# 6. Loading the saved Model and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aeeaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "# Load Fine-tuning model\n",
    "loaded_tokenizer = BertTokenizerFast.from_pretrained(MODEL_SAVE_PATH)\n",
    "loaded_model = TFBertForSequenceClassification.from_pretrained(MODEL_SAVE_PATH)\n",
    "\n",
    "text_classifier = TextClassificationPipeline(\n",
    "    tokenizer=loaded_tokenizer, \n",
    "    model=loaded_model, \n",
    "    framework='tf',\n",
    "    return_all_scores=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce66cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(columns=['file_name', 'class'])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3c3c8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/aiffel/data/test.json', 'r') as f:\n",
    "    test_json = json.load(f)\n",
    "    \n",
    "# test_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8460ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "answer_dict = {}\n",
    "for file_name, text in tqdm(test_json.items()):\n",
    "    preds_list = text_classifier(text['text'])[0]\n",
    "    best_label = int(sorted(preds_list, key=lambda x : x['score'])[-1]['label'].split('_')[-1])\n",
    "    answer_dict[file_name] = best_label\n",
    "          \n",
    "answer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6add4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in answer_dict.items():\n",
    "    test_df = test_df.append({'file_name': key, 'class': value}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90608373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df.to_csv(\"HanBERT.csv\")  # accuracy - 0.9125\n",
    "# test_df.to_csv(\"HanBERT_ver2.csv\")  # accuracy - 0.875\n",
    "# test_df.to_csv(\"HanBERT_ver4.csv\") # accuracy - 0.8975\n",
    "# test_df.to_csv(\"HanBERT_ver5.csv\") # accuracy - 0.91\n",
    "# test_df.to_csv(\"HanBERT_ver6.csv\") # accuracy - 0.885\n",
    "test_df.to_csv(\"klue_BERT_ver7.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023f61f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eab8c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92de47d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838b2444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ba9b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a0d5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
