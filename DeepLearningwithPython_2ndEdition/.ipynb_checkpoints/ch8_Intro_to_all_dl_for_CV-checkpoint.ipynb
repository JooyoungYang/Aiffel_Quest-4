{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "334da76d",
   "metadata": {},
   "source": [
    "## 8 컴퓨터 비전을 위한 딥러닝\n",
    "\n",
    "1 합성곱 신경망 소개 <br>\n",
    "2 소규모 데이터셋에서 밑바닥부터 컨브넷 훈련하기 <br>\n",
    "3 사전 훈련된 모델 활용하기 <br>\n",
    "4 요약 <br><br>\n",
    "\n",
    "컴퓨터 비전은 2011~2015년 사이의 초기 딥러닝의 부흥을 이끈 영역 <br>\n",
    "합성곱 신경망(Convolutional Neural Network)라고 부르는 딥러닝 모델의 종류가 그 당시 이미지 분류 대회에서 좋은 결과를 얻었음 <br><br>\n",
    "\n",
    "\n",
    "### 8.1 합성곱 신경망 소개\n",
    "여기서는 컨브넷 정의와 컨브넷이 컴퓨터 비전 관련 작업에 잘 맞는 이유에 대한 이론적배경 <br>\n",
    "2장에서 밀집 연결신경망으로 풀었던 정확도는 97.8%, MNIST 숫자 이미지 분류에 컨브넷을 사용할 예정이고 성능이 다를 예정\n",
    "\n",
    "#### 코드 8-1 간단한 컨브넷 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d7668c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation='relu')(inputs)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(10, activation='softmax')(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df2fb72",
   "metadata": {},
   "source": [
    "컨브넷이 배치 차원을 제외하고 (image_height, image_width, image_channles) 크기의 입력 텐서를 사용한다는 점이 중요하다, <br>\n",
    "이 예제에서는 MNIST 이미지 포맷인 (28, 28, 1) 크기의 입력 텐서를 처리하도록 설정해야 한다. \n",
    "\n",
    "#### 코드 8-2 모델의 summary() 메서드 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0911b34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                11530     \n",
      "=================================================================\n",
      "Total params: 104,202\n",
      "Trainable params: 104,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f852a65d",
   "metadata": {},
   "source": [
    "- Conv2D와 MaxPooling2D층의 출력은 (height, width, channels) 크기의 rank-3 tensor <br>\n",
    "- 높이와 너비 차원은 모델이 깊어질수록 작아지는 경향이 있다. <br>\n",
    "- 채널의 수는 Conv2D층에 전달된 첫번쨰 매개변수에 의해 조절됨 (32개, 64개, 128개), <br>\n",
    "- 마지막 Conv2D 층의 출력크기는 (3,3, 128)이다. 즉, 128개의 채널을 가진 3*3 크기의 특성 맵(feature map)이다. <br>\n",
    "- 그 다음 단계는 이 출력을 밀집 연결 분류기로 주입한다. 이 분류기는 1D 벡터를 처리하는데 이전 층이 rank-3 tensor라서 Dense층 이전에 Flatten 층으로 먼저 3D출력을 1D 텐서로 펼쳐야한다<br>\n",
    "- 마지막으로 10개의 클래스를 분류하기 위해 마지막층의 출력 크기를 10으로 하고 소프트맥스 활성화 함수를 사용한다 <br><br>\n",
    "\n",
    "\n",
    "위에 만들어놓은 모델로 MNIST를 훈련하겠다, 2장의 MNIST 예제 코드를 많이 재사용할 것임 <br>\n",
    "소프트 맥스 활성화 함수의 출력을 바탕으로 10개의 클래스를 분류하기 떄문에 범주형 크로스엔트로피 손실을 사용할것임 <br>\n",
    "레이블이 정수이므로 희소한 크로스엔트로피 손실인 sparse_categorical_crossentropy를 사용할 것임 <br>\n",
    "#### 코드 8-3 MNIST 이미지에서 컨브넷 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62f9805b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 69s 72ms/step - loss: 0.1582 - accuracy: 0.9506\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 67s 72ms/step - loss: 0.0446 - accuracy: 0.9861\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 67s 72ms/step - loss: 0.0305 - accuracy: 0.9912\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.0227 - accuracy: 0.9931\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.0186 - accuracy: 0.9945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faa0c4292e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype(\"float32\")/255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype(\"float32\")/255\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "             loss=\"sparse_categorical_crossentropy\",\n",
    "             metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e9487c",
   "metadata": {},
   "source": [
    "테스트 데이터에서 모델을 평가한다. \n",
    "\n",
    "#### 코드 8-4 컨브넷 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55d459b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 11ms/step - loss: 0.0268 - accuracy: 0.9918\n",
      "테스트 정확도: 0.992\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"테스트 정확도: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db79dc6d",
   "metadata": {},
   "source": [
    "2장의 완전 연결네트워크는 97.8%의 테스트 정확도를 얻은 반면 기본적인 컨브넷은 99.1%의 테스트 정확도를 얻었다. 왜그럴까?\n",
    "\n",
    "\n",
    "### 8.1.1 합성곱 연산\n",
    "Dene층은 입력 특성 공간에 있는 전역 패턴(ex, MNIST 숫자 이미지에서는 모든 픽셀에 걸친 패턴)을 학습하지만 합성곱 층은 지역 패턴을 학습한다,\n",
    "이미지일 경우 작은 2D 윈도우로 입력에서 패턴을 찾는다. 앞의 예에서 이 윈도우는 모두 3*3의 크기였음 <br>\n",
    "\n",
    "- 학습된 패턴은 평행 이동 불변성(translation invariant)을 가짐 <br>: 컨브넷이 이미지의 오른쪽 아래 모서리에서 어떤 패턴을 학습했다면 다른곳에서도 이 패턴을 인식할 수 있다. Fully Connected Layer에서는 새로운 위치에 나타난 것은 새로운 패턴으로 학습해야한다. 이런 성질은 컨브넷이 이미지를 효율적으로 처리하게 만들어준다(근본적으로 우리가 보는 세상은 평행 이동으로 인해 다르게 인식되지 않는다). 적은 수의 훈련 샘플을 사용해서 일반화 능력을 가진 표현을 학습할 수 있다. <b>근본적으로 우리가 보는 세상은 평행 이동으로 인해 다르게 인식되지 않는다</b> <br>\n",
    "- 컨브넷은 패턴의 공간적 계층 구조를 학습할 수 있음 <br>: 첫 번째 합성곱 층이 edge같은 작은 지역 패턴을 학습한다. 2번째 합성곱 층은 첫번쨰 층의 특성으로 구성된 더  성된 더 큰 패턴을 학습하는 식. 이런 방식을 사용하여 컨브넷은 매우 복잡하고 추상적인 시각적 개념을 효과적으로 학습할 수 있음, <b>근본적으로 우리가 보는 세상은 공간적 계층 구조를 가지고 있기 때문</b> <br>\n",
    "    - 합성곱 연산은 특성 맵(feature map)이라고 부르는 rank-3 tensor에 적용 <br>\n",
    "    - 2개의 공간 축(높이와 너비)과 깊이 축(채널축이라고도 부름) <br>\n",
    "    - RGB 이미지는 3개의 컬러 채널(빨간색, 녹색, 파란색)을 가지므로 깊이 축의 차원이 3이 됨 <br>\n",
    "    - MNIST 숫자처럼 흑백 이미지는 깊이 축의 차원이 1(gray scale)임\n",
    "    - 합성곱 연산은 입력 특성맵에서 작은 패치(patch)들을 추출하고 이런 모든 패치에 같은 변환을 적용하여 축력 특성 맵(output feature map)을 만듦 <br>\n",
    "    - 출력 텐서의 깊이는 층의 매개변수로 결정되기 때문에 상황에 따라 다름, 이렇게 되면 깊이 축의 채널은 더 이상 RGB 입력처럼 특정 컬러를 의미하지 않는다. 그 대신 일종의 filter를 의미함. 필터는 입력 데이터의 어떤 특성을 인코딩, ex) 고수준으로 보면 하나의 필터가 '입력에 얼굴이 있는지'를 인토딩 할 수 있다. <br>\n",
    "    - MNIST 예제에서는 첫번째 합성곱 층이 (28, 28, 1) 크기의 특성 맵을 입력으로 받아 (26, 26, 32) 크기의 특성 맵을 출력함. <br>\n",
    "    - 즉, 입력에 대해 32개의 필터를 적용함, 32개의 출력 채널 각각은 26*26 크기의 배열 값을 가짐, 이 값은 입력에 대한 필터의 응답맵 (response map)이다. 입력의 각 위치에서 필터 패턴에 대한 응답을 나타냄. <br>\n",
    "    - 특성 맵이란 말이 의미하는 것은 다음과 같다: 각 차원은 하나의 특성( 또는 필터)이고 rank-2 tensor인 output[:, :, n]은 입력에 대한 이 필터 응답을 나타내는 2d 공간상의 map이다. <br>\n",
    "    - 핵심적인 2개의 파라미터로 정의 됨 <br>:\n",
    "        - <b> 입력으로부터 뽑아낼 패치의 크기</b>: 전형적으로 3*3 or 5*5 크기를 사용 <br>\n",
    "        - <b> 특성 맵의 출력 깊이</b>: 합성곱으로 계산한 필터 개수, 여기서는 깊이 32로 시작해서 깊이 128로 끝남 <br>\n",
    "\n",
    "연산과정\n",
    "케라스의 Conv2D층에서 이 파라미터는 Conv2D(ouput_depth, (window_height, window_width))처럼 첫번째와 두번쨰 매개변수로 전달 <br>\n",
    "↓ <br>\n",
    "3D 입력 특성 맵 위를 3*3 or 5*5 크기의 윈도우가 sliding 하면서 모든 위치에서 3D 특성 패치 ((window_height, window_width, input_depth) 크기)를 추출하는 방식으로 합성곱이 작동 <br>\n",
    ": 이런 3D 패치는 합성곱 커널(convolution kernel)이라고 불리는 하나의 하습된 가중채 행렬과의 텐서곱셈을 통해 (output_depth,) 크기의 1D 벡터로 변환 <br>\n",
    "↓ <br>\n",
    "동일한 커널이 모든 패치에 걸쳐서 재사용 <br>\n",
    "↓ <br>\n",
    "변환된 모든 벡터는 (height, width, output_depth) 크기의 3D 특성 맵으로 재구성 <br>\n",
    "↓ <br>\n",
    "출력 특성 맵의 공간산 위치는 입력 특성 맵의 같은 위치에 대응됨 <br>\n",
    "↓ <br>\n",
    "3*3 윈도우를 사용하면 3D 패치 input[i-1:i+2, j-1:j+2, :] 로부터 벡터 output[i, j, :]가 만들어짐 <br><br>\n",
    "\n",
    "** 여기서 2가지 이유로 출력 높이와 너비는 입력의 높이, 너비와 다를 수 있음 **\n",
    "- 경계 문제: 입력 특성 맵에 패딩을 추가하여 대응 할 수 있음 <br>\n",
    "- stride의 사용 여부에 따라 다름 <br>\n",
    "\n",
    "\n",
    "#### 경계 문제와 패딩 이해하기\n",
    "- 5*5 크기의 특성 맵을 생각 해볼때, 3*3 크기의 총 9개의 격자를 형성하니, 크기가 조금 줄어든다. <br>\n",
    "- 입력과 동일한 높이와 너비를 가진 출력 특성 맵을 얻고 싶다면 패딩(padding)을 사용할 수 있음 <br>\n",
    "- Conv2D층에서 패딩은 padding 매개변수로 설정 할 수 있고 2개의 값이 가능함<br>\n",
    "- \"valid\"는 패딩을 사용하지 않는다는 뜻, \"same\"은 \"입력과 동일한 높이와 너비를 가진 출력을 만들기 위해 패딩한다\"라는 뜻. padding 매개변수의 기본값은 \"valid\"이다. <br>\n",
    "\n",
    "#### 합성곱 스트라이드 이해하기 \n",
    "출력 크기에 영향을 미치는 다른 요소는 스트라이드이다. 두 번의 연속적인 위도우 사이의 거리가 stride라고 불리는 합성곱의 파라미터이다, 기본값은 1이다. 스트라이드가 1보다 큰 스트라이드 합성곱도 가능함. <br>\n",
    "- ex) stride=2라는 뜻은 특성 맵의 너비와 높이가 2의 배수로 downsampling 되었다는 뜻, 스트라이드 합성곱은 분류 모델에서 드물게 사용된다. <br>\n",
    "- 분류 모델에서는 특성 맵을 다운샘플링하기 위해 stride 대신 max pooling연산을 사용하는 경우가 많다 <br>\n",
    "\n",
    "\n",
    "#### 8.1.2 최대 풀링 연산\n",
    "- 최대 풀링은 입력 특성 맵에서 윈도우에 맞는 패치를 추출하고 각 채널별로 최댓값을 출력 <br>\n",
    "- 합성곱과 개념적으로 비슷하지만 추출한 패치에 학습된 선형변환(합성곱 커널을 적용하는 대신 하드코딩된 최댓값 추출 연산을 사용함 <br>\n",
    "\n",
    "#### 코드 8-5 최대 풀링 층이 빠진 잘못된 구조의 컨브넷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0be83bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 22, 22, 128)       73856     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 61952)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                619530    \n",
      "=================================================================\n",
      "Total params: 712,202\n",
      "Trainable params: 712,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation='relu')(inputs)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation='relu')(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "outputs = layers.Dense(10, activation='softmax')(x)\n",
    "model_no_max_pool = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model_no_max_pool.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a679f7e7",
   "metadata": {},
   "source": [
    "위 설정에는 2가지 문제가 있음\n",
    "\n",
    "- 특성의 공간적 계층 구조를 학습하는 데 도움이 되지 않는다, 3번째 층의 3*3 윈도우는 초기 입력의 7*7 윈도우 영역에 대한 정보만 담고 있다, 3번째 층의 3*3 윈도우는 초기 입력의 7*7 윈도우 영역에 대한 정보만 담고 있다. 마지막 합성곱 층의 특성이 전체 입력에 대하 정보를 가지고 있어야 한다. <br>\n",
    "- 작은 모델치고는 너무 많은 가중치고, 심각한 과대적합이 발생할 것 <br>\n",
    "\n",
    "downsampling을 하는 이유는 처리할 특성 맵의 가중치 개수를 줄이기 위해서이다. 또한, 연속적인 합성곱 층이 (원본 입력에서 커버되는 영역 측면에서) 점점 커진 윈도우를 통해 바라보도록 만들어진 필터의 공간적인 계층 구조를 구성한다. <br><br>\n",
    "\n",
    "*** 그 외 방법들 ***\n",
    "1) 합성곱 층에서 스트라이드를 사용할 수 있음 <br>\n",
    "2) 입력 패치의 채널별 평균값을 계산항 변환하는 평균 풀링(average pooling) <br>\n",
    "    - 최대 풀링이 다른 방법들보다 더 잘 작동하는 편, 그 이유는 특성이 특성 맵의 각 타일에서 어떤 패턴이나 개념의 존재 여부를 인코딩하는 경향이 있기 때문, that's why it is called 특성의 지도 (map) <br>\n",
    "3) Best (가장 납득할 만한 서브샘플링 전략은 먼저 (Stride가 없는 합성굡으로) 조밀한 특성 맵을 만들고 그 다음 작은 패치에 대해 최대로 활성화된 특성을 고르는 것 <br><br>\n",
    "\n",
    "\n",
    "## 8.2 소규모 데이터셋에서 밑바닥부터 컨브넷 훈련하기\n",
    "- 데이터 증식(data augmentation)방법 <br>\n",
    "- 사전 훈련된 네트워크로 특성을 추출하는 것(97.5%의 정확도를 얻게 됨)과 사전 훈련된 네트워크를 세밀하게 튜닝하는 것(최종 모델은 09.5% 정확도를 얻을 것) <br>\n",
    "=> 위 3가지 전략은 반드시 알고 있어야함 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661652a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123325e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216709e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9178a4f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fb4e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8aae48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10823e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00301560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac904ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0be89ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912fbb1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8161c4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc308a33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
